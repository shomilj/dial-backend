{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "planned-aruba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import twint\n",
    "import json\n",
    "import openai\n",
    "from textblob import TextBlob\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "default_keywords=[\"trump\", \"impeachment\", \"bachelor\", \"covid\"]\n",
    "elonmusk = ['dogecoin', 'POTUS', 'cleantechnica', 'TheOnion', 'TheBabylonBee', 'karpathy', 'Astro_Soichi', 'PopMech', 'PyTorch', 'Nigel_Lockyer', 'jagarikin', 'AstroVicGlover', 'Grimezsz', 'TashaARK']\n",
    "satyanadella = ['Herbert_Diess', 'ChrstnKlein', 'vasujakkal', 'amandaksilver', 'nicoledezen', 'KingJames', 'drhew', 'panos_panay', 'youngdchris', 'MicrosoftWomen']\n",
    "stephencurry = ['BryceCash6', 'Patty_Mills', 'RealDealBeal23', 'gusjohnson', 'arneduncan', 'PatrikFrisk', 'iamcarljones', 'zlurie', 'TSM', 'QCook323']\n",
    "kamalaharris = ['LaCasaBlanca', 'SecondGentleman', 'FLOTUS', 'POTUS', 'WhiteHouse', 'SenatorHick', 'RepBowman', 'RepRitchie', 'AlexPadilla4CA', 'AstroAnnimal', 'CASOSvote', 'CAPAction', 'RobBontaCA']\n",
    "openai.api_key = \"sk-8xLMvhl5qyjjmajkSRQeEuggYQTdspJViTCInd9Y\"\n",
    "\n",
    "def get_tweets(keyword, num_posts, likes, retweets):\n",
    "    c = twint.Config()\n",
    "    c.Limit = num_posts\n",
    "    if(keyword.strip()):\n",
    "        c.Search = keyword\n",
    "        c.Language = \"en\"\n",
    "        c.Pandas = True\n",
    "        c.Store_object = False\n",
    "        c.Hide_output = True\n",
    "        c.User_full = True\n",
    "        c.Min_likes = likes\n",
    "        c.Min_retweets = retweets\n",
    "        twint.run.Search(c)\n",
    "        tweets = twint.storage.panda.Tweets_df\n",
    "        return tweets\n",
    "    else:\n",
    "        individual_tweets = []\n",
    "        for keyword in default_keywords:\n",
    "            c.Search = keyword\n",
    "            c.Language = \"en\"\n",
    "            c.Pandas = True\n",
    "            c.Store_object = False\n",
    "            c.Hide_output = True\n",
    "            c.User_full = True\n",
    "            c.Min_likes = likes\n",
    "            c.Min_retweets = retweets\n",
    "            twint.run.Search(c)\n",
    "            tweets = twint.storage.panda.Tweets_df\n",
    "            individual_tweets.append(tweets)\n",
    "        all_tweets = pd.concat(individual_tweets)\n",
    "        return all_tweets\n",
    "    \n",
    "def get_controversial(keyword, num_posts, likes, retweets):\n",
    "    textblob = get_tweets(keyword, num_posts, likes, retweets)\n",
    "    textblob['tweet'] = textblob['tweet'].astype(str)\n",
    "    polarity = lambda x: TextBlob(x).sentiment.polarity\n",
    "    subjectivity = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "    textblob['polarity'] = textblob['tweet'].apply(polarity)\n",
    "    textblob['subjectivity'] = textblob['tweet'].apply(subjectivity)\n",
    "\n",
    "    controversial_tweets = textblob[textblob['polarity'] > 0.5]\n",
    "    return controversial_tweets\n",
    "\n",
    "def get_explained(keyword, num_posts, likes, retweets):\n",
    "    tweets = get_tweets(keyword, num_posts, likes, retweets)\n",
    "    is_explanation = []\n",
    "    for i in range(0, len(tweets)):\n",
    "        tweettxt = tweets['tweet'][i]\n",
    "        if 'explain' in tweettxt:\n",
    "            is_explanation.append(True)\n",
    "        else: \n",
    "            is_explanation.append(False)\n",
    "    tweets['is_explanation'] = is_explanation\n",
    "    explained_tweets = tweets[tweets['is_explanation'] == True]\n",
    "    return explained_tweets\n",
    "\n",
    "def get_verified(keyword, num_posts, likes, retweets):\n",
    "    c = twint.Config()\n",
    "    c.Limit = num_posts\n",
    "    if (keyword.strip()):\n",
    "        c.Search = keyword\n",
    "        c.Language = \"en\"\n",
    "        c.Verified = True\n",
    "        c.Pandas = True\n",
    "        c.Store_object = False\n",
    "        c.Hide_output = True\n",
    "        c.User_full = True\n",
    "        c.Min_likes = likes\n",
    "        c.Min_retweets = retweets\n",
    "        twint.run.Search(c)\n",
    "        verified_tweets = twint.storage.panda.Tweets_df\n",
    "        return verified_tweets\n",
    "    else:\n",
    "        individual_tweets = []\n",
    "        for keyword in default_keywords:\n",
    "            c.Search = keyword\n",
    "            c.Language = \"en\"\n",
    "            c.Pandas = True\n",
    "            c.Store_object = False\n",
    "            c.Hide_output = True\n",
    "            c.User_full = True\n",
    "            c.Verified = True\n",
    "            c.Min_likes = likes\n",
    "            c.Min_retweets = retweets\n",
    "            twint.run.Search(c)\n",
    "            tweets = twint.storage.panda.Tweets_df\n",
    "            individual_tweets.append(tweets)\n",
    "        all_tweets = pd.concat(individual_tweets)\n",
    "        return all_tweets \n",
    "\n",
    "def get_viral(keyword, num_posts):\n",
    "    c = twint.Config()\n",
    "    c.Limit = num_posts\n",
    "    c.Language = \"en\"\n",
    "    c.Min_likes = 50000\n",
    "    c.Min_retweets = 1000\n",
    "    c.Min_replies = 1000\n",
    "    if(keyword.strip()):\n",
    "        c.Search = keyword\n",
    "        c.Pandas = True\n",
    "        c.Store_object = False\n",
    "        c.Hide_output = True\n",
    "        c.User_full = True\n",
    "        twint.run.Search(c)\n",
    "        viral_tweets = twint.storage.panda.Tweets_df\n",
    "        return viral_tweets\n",
    "    else:\n",
    "        individual_tweets = []\n",
    "        for keyword in default_keywords:\n",
    "            c.Search = keyword\n",
    "            c.Pandas = True\n",
    "            c.Store_object = False\n",
    "            c.Hide_output = True\n",
    "            c.User_full = True\n",
    "            twint.run.Search(c)\n",
    "            tweets = twint.storage.panda.Tweets_df\n",
    "            individual_tweets.append(tweets)\n",
    "        all_tweets = pd.concat(individual_tweets)\n",
    "        return all_tweets \n",
    "\n",
    "def get_user_tweets(username, keyword, num_posts):\n",
    "    c = twint.Config()\n",
    "    c.Pandas = True\n",
    "    c.Search = keyword\n",
    "    c.Store_object = False\n",
    "    c.Hide_output = True\n",
    "    c.Limit = num_posts\n",
    "    c.Username = username\n",
    "    twint.run.Search(c)\n",
    "    tweets = twint.storage.panda.Tweets_df\n",
    "    return tweets\n",
    "    \n",
    "    \n",
    "def get_influencer_feed(username, keyword, num_posts):\n",
    "    following = []\n",
    "    if username == 'elonmusk':\n",
    "        following = elonmusk\n",
    "    elif username == 'satyanadella':\n",
    "        following = satyanadella\n",
    "    elif username == 'StephenCurry30':\n",
    "        following = stephencurry\n",
    "    elif username == 'VP':\n",
    "        following = kamalaharris\n",
    "\n",
    "    individual_tweets = []\n",
    "    for user in following:\n",
    "        tweets = get_user_tweets(user, keyword, num_posts)\n",
    "        individual_tweets.append(tweets)\n",
    "    all_tweets = pd.concat(individual_tweets)\n",
    "    return all_tweets\n",
    "\n",
    "def get_openai_positive(keyword, num_posts, likes, retweets):\n",
    "    tweets = get_tweets(keyword, num_posts, likes, retweets)\n",
    "    is_positive = []\n",
    "    for i in range(0, len(tweets)):\n",
    "        tweettxt = tweets['tweet'][i]\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"davinci\",\n",
    "          prompt=f\"Social media post: \\\"{tweettxt}\\\"\\nSentiment (positive, neutral, negative):\",\n",
    "          temperature=0,\n",
    "          max_tokens=1,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        sentiment = response[\"choices\"][0][\"text\"]\n",
    "        if ('positive' in sentiment.lower()):\n",
    "            is_positive.append(True)\n",
    "        else:\n",
    "            is_positive.append(False)\n",
    "    tweets['is_positive'] = is_positive\n",
    "    positive_tweets = tweets[tweets['is_positive'] == True]\n",
    "    return positive_tweets\n",
    "\n",
    "def get_openai_negative(keyword, num_posts, likes, retweets):\n",
    "    tweets = get_tweets(keyword, num_posts, likes, retweets)\n",
    "    is_negative = []\n",
    "    for i in range(0, len(tweets)):\n",
    "        tweettxt = tweets['tweet'][i]\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"davinci\",\n",
    "          prompt=f\"Social media post: \\\"{tweettxt}\\\"\\nSentiment (positive, neutral, negative):\",\n",
    "          temperature=0,\n",
    "          max_tokens=1,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        sentiment = response[\"choices\"][0][\"text\"]\n",
    "        if ('negative' in sentiment.lower()):\n",
    "            is_negative.append(True)\n",
    "        else:\n",
    "            is_negative.append(False)\n",
    "    tweets['is_negative'] = is_negative\n",
    "    negative_tweets = tweets[tweets['is_negative'] == True]\n",
    "    return negative_tweets\n",
    "\n",
    "def get_openai_neutral(keyword, num_posts, likes, retweets):\n",
    "    tweets = get_tweets(keyword, num_posts, likes, retweets)\n",
    "    is_neutral = []\n",
    "    for i in range(0, len(tweets)):\n",
    "        tweettxt = tweets['tweet'][i]\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"davinci\",\n",
    "          prompt=f\"Social media post: \\\"{tweettxt}\\\"\\nSentiment (positive, neutral, negative):\",\n",
    "          temperature=0,\n",
    "          max_tokens=1,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        sentiment = response[\"choices\"][0][\"text\"]\n",
    "        if ('neutral' in sentiment.lower()):\n",
    "            is_neutral.append(True)\n",
    "        else:\n",
    "            is_neutral.append(False)\n",
    "    tweets['is_neutral'] = is_neutral\n",
    "    neutral_tweets = tweets[tweets['is_neutral'] == True]\n",
    "    return neutral_tweets\n",
    "\n",
    "def get_tweets_using_algorithm(algorithm, keyword, likes=100, retweets=50):\n",
    "    num_posts = 100\n",
    "    if('controversial' in algorithm):\n",
    "        tweets = get_controversial(keyword, num_posts, likes, retweets)\n",
    "    elif('explained' in algorithm):\n",
    "        tweets = get_explained(keyword, 1000, 0, 0)\n",
    "    elif('influencer' in algorithm):\n",
    "        _, username = algorithm.split(\"-\", 1)\n",
    "        tweets = get_influencer_feed(username, keyword, num_posts)\n",
    "    elif('viral' in algorithm):\n",
    "        tweets = get_viral(keyword, 100)\n",
    "    elif('verified' in algorithm):\n",
    "        tweets = get_verified(keyword, 100, likes, retweets)\n",
    "    elif('positive' in algorithm):\n",
    "        tweets = get_openai_positive(keyword, 100, likes, retweets)\n",
    "    elif('negative' in algorithm):\n",
    "        tweets = get_openai_negative(keyword, 100, likes, retweets)\n",
    "    elif('neutral' in algorithm):\n",
    "        tweets = get_openai_neutral(keyword, 100, likes, retweets)\n",
    "    else:\n",
    "        tweets = pd.DataFrame()\n",
    "    filtered = tweets[['conversation_id', 'created_at', 'tweet', 'user_id', 'username', 'name', 'nlikes', 'nreplies', 'nretweets']]\n",
    "    filtered.reset_index(drop=True, inplace=True)\n",
    "    result = filtered.to_json(orient=\"index\")\n",
    "    parsed = list(json.loads(result).values())\n",
    "    json_tweets = json.dumps(parsed, indent=4)\n",
    "    return json_tweets\n",
    "\n",
    "json_tweets = get_tweets_using_algorithm('neutral', 'bachelor')\n",
    "print(json_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "influencer_tweets = get_tweets_using_algorithm('influencer-elonmusk', '')\n",
    "controversial_tweets = get_tweets_using_algorithm('controversial', 'trump')\n",
    "explained_tweets = get_tweets_using_algorithm('explained', 'bachelor')\n",
    "verified_tweets = get_tweets_using_algorithm('verified', 'impeach')\n",
    "viral_tweets = get_tweets_using_algorithm('viral', 'impeach')\n",
    "positive_tweets = get_tweets_using_algorithm('positive', '')\n",
    "negative_tweets = get_tweets_using_algorithm('negative', '')\n",
    "neutral_tweets = get_tweets_using_algorithm('neutral', '')\n",
    "\n",
    "#explained no keyword, positive/negative/neutral no keyword"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
